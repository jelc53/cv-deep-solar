{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import copy\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import Inception3\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/deepsolar/src/\")\n",
    "\n",
    "from inception_modified import InceptionSegmentation\n",
    "from image_dataset import ImageFolderModified, ImageFolderModifiedEvaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# directory for loading training/validation/test data\n",
    "mode = 'val' # 'eval' or 'val'\n",
    "# data_dir = '/home/ubuntu/deepsolar/data/ds-usa/eval'  #'/home/ubuntu/projects/deepsolar/deepsolar_dataset_toy/test'\n",
    "data_dir = '/home/ubuntu/deepsolar/data/ds-france/google/ft_5000/val'\n",
    "# data_dir = '/home/ubuntu/deepsolar/data/ds-france/google/ft_100/val/' \n",
    "classification_path = '/home/ubuntu/deepsolar/checkpoint/ft_5000_classification_tune_sweep_best_models/psel_0-6956991453638643_lr_0-00016152257047812214_lr_decay_rate_0-3042236746546522_weight_decay_0-16265604808312772_epoch__8_last.tar'\n",
    "segmentation_path = '/home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 299\n",
    "batch_size = 1   # must be 1 for testing segmentation\n",
    "class_threshold = 0.5  # threshold probability to identify am image as positive\n",
    "true_cam_threshold = 0.5\n",
    "seg_threshold = 0.82    # threshold to identify a pixel as positive.\n",
    "level = 2\n",
    "cam_filepath = 'CAM_ft_5000_finetune_test.pickle' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "                 transforms.Resize((input_size, input_size)),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(stats):\n",
    "    return (stats['TP'] + 0.00001) * 1.0 / (stats['TP'] + stats['FP'] + 0.00001)\n",
    "                           \n",
    "def recall(stats):\n",
    "    return (stats['TP'] + 0.00001) * 1.0 / (stats['TP'] + stats['FN'] + 0.00001)\n",
    "\n",
    "def f1_score(stats):\n",
    "    prec = precision(stats)\n",
    "    rec = recall(stats)\n",
    "    print('precision: ' + str(prec))\n",
    "    print('recall: ' + str(rec)) \n",
    "    print('stats: ')\n",
    "    print(stats)\n",
    "    f1 = (prec * rec) / (prec + rec)\n",
    "    return f1\n",
    "\n",
    "def metrics(stats):\n",
    "    \"\"\"\n",
    "    Self-defined metrics function to evaluate and compare models\n",
    "    stats: {'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN}\n",
    "    return: must be a single number \"\"\"\n",
    "    accuracy = (stats['TP'] + stats['TN']) / (stats['TP'] + stats['FP'] + stats['TN'] + stats['FN'])\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test_model(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold):\n",
    "    stats = {'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0}\n",
    "    estimated_area = 0\n",
    "    true_area = 0\n",
    "    model.eval()\n",
    "    CAM_list = []\n",
    "    iou = []\n",
    "    count = 0\n",
    "    for inputs, labels, paths in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            _, outputs, CAM = model(inputs, testing=True)   # CAM is a 1 x 35 x 35 activation map\n",
    "            prob = F.softmax(outputs, dim=1)\n",
    "            preds = prob[:, 1] >= class_threshold\n",
    "\n",
    "        CAM = CAM.squeeze(0).cpu().numpy()   # transform tensor into numpy array\n",
    "        for i in range(preds.size(0)):\n",
    "            predicted_label = preds[i] \n",
    "            # if labels[i]==1: # oracle to see how much improving classification would improve estimation\n",
    "            if predicted_label.cpu().item():\n",
    "                CAM_list.append((CAM, paths[i]))        # only use the generated CAM if it is predicted to be 1\n",
    "                CAM_rescaled = (CAM - CAM.min()) / (CAM.max() - CAM.min())    # get predicted area\n",
    "                CAM_pred = CAM_rescaled > seg_threshold\n",
    "                pred_pixel_area = np.sum(CAM_pred)\n",
    "                estimated_area += pred_pixel_area\n",
    "                \n",
    "            else:\n",
    "                CAM_list.append((np.zeros_like(CAM), paths[i]))  # otherwise the CAM is a totally black one\n",
    "                CAM_pred = np.zeros_like(CAM)\n",
    "\n",
    "            if labels[i] == 1:\n",
    "                # calculate true area\n",
    "                img_path = os.path.splitext(paths[i])\n",
    "                true_seg_path = img_path[0] + '_true_seg' + img_path[1]\n",
    "                true_seg_img = Image.open(true_seg_path)\n",
    "                transform = transforms.Compose([transforms.ToTensor()])\n",
    "                true_seg = transform(true_seg_img)\n",
    "                true_seg = true_seg.squeeze(0).cpu().numpy()\n",
    "                true_pixel_area = np.sum(true_seg)\n",
    "                true_pixel_area = true_pixel_area * (35. * 35.) / (true_seg.shape[0] * true_seg.shape[1])\n",
    "                true_area += true_pixel_area\n",
    "                CAM_true = skimage.transform.resize(true_seg, (35,35))\n",
    "                CAM_true = CAM_true > true_cam_threshold\n",
    "\n",
    "            else:\n",
    "                CAM_true = np.zeros_like(CAM)\n",
    "\n",
    "        intersection = CAM_true * CAM_pred\n",
    "        union = CAM_true + CAM_pred\n",
    "        if union.sum() > 0:\n",
    "            iou.append(intersection.sum() / float(union.sum()))\n",
    "\n",
    "        stats['TP'] += torch.sum((preds == 1) * (labels == 1)).cpu().item()\n",
    "        stats['TN'] += torch.sum((preds == 0) * (labels == 0)).cpu().item()\n",
    "        stats['FP'] += torch.sum((preds == 1) * (labels == 0)).cpu().item()\n",
    "        stats['FN'] += torch.sum((preds == 0) * (labels == 1)).cpu().item()\n",
    "\n",
    "\n",
    "    metric_value = metrics(stats)\n",
    "    print('IOU: ' + str(np.mean(iou)))\n",
    "    return stats, metric_value, CAM_list, estimated_area, true_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_val(segmentation_path, seg_threshold, cam_filepath):\n",
    "    mode = 'val'\n",
    "    if mode=='eval':\n",
    "        print('evaluating on test set')\n",
    "        dataset_test = ImageFolderModifiedEvaluation(data_dir, transform_test)\n",
    "    else:\n",
    "        dataset_test = ImageFolderModified(data_dir, transform_test)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # model\n",
    "    model = InceptionSegmentation(num_outputs=2, level=level)\n",
    "    model.load_existing_params(segmentation_path)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    stats, metric_value, CAM_list, estimated_area, true_area = test_model(model, dataloader_test, metrics, class_threshold=class_threshold, seg_threshold=seg_threshold, true_cam_threshold=true_cam_threshold)\n",
    "    precision = (stats['TP'] + 0.00001) * 1.0 / (stats['TP'] + stats['FP'] + 0.00001)\n",
    "    recall = (stats['TP'] + 0.00001) * 1.0 / (stats['TP'] + stats['FN'] + 0.00001)\n",
    "    print('metric value: '+str(metric_value))\n",
    "    print('precision: ' + str(round(precision, 4)))\n",
    "    print('recall: ' + str(round(recall, 4)))\n",
    "    print('estimated_area: ' + str(estimated_area))\n",
    "    print('true_area: ' + str(true_area))\n",
    "    print('ratio (est / true): ' + str(estimated_area / true_area))\n",
    "    print('error ((est - true) / true): ' + str((estimated_area - true_area) / true_area)) \n",
    "\n",
    "    with open(cam_filepath, 'wb') as f:\n",
    "        pickle.dump(CAM_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.7###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.39307012590848595\n",
      "metric value: 0.9735\n",
      "precision: 0.9693\n",
      "recall: 0.978\n",
      "estimated_area: 27479\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.1751696576285722\n",
      "error ((est - true) / true): 0.17516965762857215\n",
      "###################Threshold:0.73###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.37725766247761694\n",
      "metric value: 0.9735\n",
      "precision: 0.9693\n",
      "recall: 0.978\n",
      "estimated_area: 22275\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.9526148740374993\n",
      "error ((est - true) / true): -0.047385125962500656\n",
      "###################Threshold:0.75###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.3647871177832733\n",
      "metric value: 0.9735\n",
      "precision: 0.9693\n",
      "recall: 0.978\n",
      "estimated_area: 19399\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.8296195708845544\n",
      "error ((est - true) / true): -0.17038042911544557\n",
      "###################Threshold:0.77###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.34470351582065245\n",
      "metric value: 0.9735\n",
      "precision: 0.9693\n",
      "recall: 0.978\n",
      "estimated_area: 16770\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.7171874943932149\n",
      "error ((est - true) / true): -0.282812505606785\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.70, 0.73, 0.75, 0.77]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.83###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.16438602448647707\n",
      "metric value: 0.9725\n",
      "precision: 0.9637\n",
      "recall: 0.982\n",
      "estimated_area: 32426\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.386733553559594\n",
      "error ((est - true) / true): 0.3867335535595939\n",
      "###################Threshold:0.85###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.16351571116811026\n",
      "metric value: 0.9725\n",
      "precision: 0.9637\n",
      "recall: 0.982\n",
      "estimated_area: 25685\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.0984472745074376\n",
      "error ((est - true) / true): 0.09844727450743752\n",
      "###################Threshold:0.87###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.15839995024739792\n",
      "metric value: 0.9725\n",
      "precision: 0.9637\n",
      "recall: 0.982\n",
      "estimated_area: 20135\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.8610954203701481\n",
      "error ((est - true) / true): -0.1389045796298519\n"
     ]
    }
   ],
   "source": [
    "segmentation_path = '/home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar'\n",
    "cam_filepath = 'CAM_list.pickle'\n",
    "for threshold in [0.83, 0.85, 0.87]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.86###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.16172722972753958\n",
      "metric value: 0.9725\n",
      "precision: 0.9637\n",
      "recall: 0.982\n",
      "estimated_area: 22774\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.9739551578599331\n",
      "error ((est - true) / true): -0.026044842140066887\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.86]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.6###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.3096922064267837\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 88825\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 3.798698818692744\n",
      "error ((est - true) / true): 2.798698818692744\n",
      "###################Threshold:0.7###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.4083960328243958\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 41117\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.7584137273086358\n",
      "error ((est - true) / true): 0.7584137273086358\n",
      "###################Threshold:0.8###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.39656591422476023\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 18102\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.7741519393861644\n",
      "error ((est - true) / true): -0.22584806061383556\n",
      "###################Threshold:0.9###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████                                                                     | 565/2000 [00:10<00:26, 54.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m [\u001b[39m0.6\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m###################Threshold:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m###################\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(threshold))\n\u001b[0;32m----> 5\u001b[0m     run_val(segmentation_path, threshold, cam_filepath)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mrun_val\u001b[0;34m(segmentation_path, seg_threshold, CAM_filepath)\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_existing_params(segmentation_path)\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m stats, metric_value, CAM_list, estimated_area, true_area \u001b[39m=\u001b[39m test_model(model, dataloader_test, metrics, class_threshold\u001b[39m=\u001b[39;49mclass_threshold, seg_threshold\u001b[39m=\u001b[39;49mseg_threshold, true_cam_threshold\u001b[39m=\u001b[39;49mtrue_cam_threshold)\n\u001b[1;32m     16\u001b[0m precision \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n\u001b[1;32m     17\u001b[0m recall \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFN\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold)\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     _, outputs, CAM \u001b[39m=\u001b[39m model(inputs, testing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)   \u001b[39m# CAM is a 1 x 35 x 35 activation map\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     prob \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     preds \u001b[39m=\u001b[39m prob[:, \u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m class_threshold\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:51\u001b[0m, in \u001b[0;36mInceptionSegmentation.forward\u001b[0;34m(self, x, testing)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, testing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     logits, intermediate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minception3(x)\n\u001b[1;32m     52\u001b[0m     feature_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvolution1(intermediate)  \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     feature_map \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(feature_map)          \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:179\u001b[0m, in \u001b[0;36mInception3_modified.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMixed_6b(x)\n\u001b[1;32m    178\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMixed_6c(x)\n\u001b[1;32m    180\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[1;32m    181\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMixed_6d(x)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:285\u001b[0m, in \u001b[0;36mInceptionC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x)\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(outputs, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:272\u001b[0m, in \u001b[0;36mInceptionC._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m branch7x7 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7_2(branch7x7)\n\u001b[1;32m    270\u001b[0m branch7x7 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7_3(branch7x7)\n\u001b[0;32m--> 272\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbranch7x7dbl_1(x)\n\u001b[1;32m    273\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_2(branch7x7dbl)\n\u001b[1;32m    274\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_3(branch7x7dbl)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:405\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 405\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m    406\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x)\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mrelu(x, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segmentation_path = '/home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar'\n",
    "cam_filepath = 'CAM_list.pickle'\n",
    "for threshold in [0.6, 0.7, 0.8, 0.9]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.73###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.4184833724038731\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 32280\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.3804897029822887\n",
      "error ((est - true) / true): 0.3804897029822886\n",
      "###################Threshold:0.75###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.4210226666473637\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 27415\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.1724326272385206\n",
      "error ((est - true) / true): 0.17243262723852051\n",
      "###################Threshold:0.77###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 42.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.41591631881830365\n",
      "metric value: 0.953\n",
      "precision: 0.9494\n",
      "recall: 0.957\n",
      "estimated_area: 23344\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.9983318347713304\n",
      "error ((est - true) / true): -0.0016681652286695962\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.73, 0.75, 0.77]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.6###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.30904415738352403\n",
      "metric value: 0.868\n",
      "precision: 0.8031\n",
      "recall: 0.975\n",
      "estimated_area: 52527\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 2.2463749265350272\n",
      "error ((est - true) / true): 1.246374926535027\n",
      "###################Threshold:0.7###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.32491767092787843\n",
      "metric value: 0.868\n",
      "precision: 0.8031\n",
      "recall: 0.975\n",
      "estimated_area: 28431\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 1.21588298468059\n",
      "error ((est - true) / true): 0.21588298468059008\n",
      "###################Threshold:0.8###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 42.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.2650837656273349\n",
      "metric value: 0.868\n",
      "precision: 0.8031\n",
      "recall: 0.975\n",
      "estimated_area: 14095\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.602788177309026\n",
      "error ((est - true) / true): -0.39721182269097405\n",
      "###################Threshold:0.9###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████▍                  | 1610/2000 [00:35<00:08, 45.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m [\u001b[39m0.6\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m###################Threshold:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m###################\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(threshold))\n\u001b[0;32m----> 6\u001b[0m     run_val(segmentation_path, threshold, cam_filepath)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mrun_val\u001b[0;34m(segmentation_path, seg_threshold, CAM_filepath)\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_existing_params(segmentation_path)\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m stats, metric_value, CAM_list, estimated_area, true_area \u001b[39m=\u001b[39m test_model(model, dataloader_test, metrics, class_threshold\u001b[39m=\u001b[39;49mclass_threshold, seg_threshold\u001b[39m=\u001b[39;49mseg_threshold, true_cam_threshold\u001b[39m=\u001b[39;49mtrue_cam_threshold)\n\u001b[1;32m     16\u001b[0m precision \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n\u001b[1;32m     17\u001b[0m recall \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFN\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m     prob \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     preds \u001b[39m=\u001b[39m prob[:, \u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m class_threshold\n\u001b[0;32m---> 18\u001b[0m CAM \u001b[39m=\u001b[39m CAM\u001b[39m.\u001b[39;49msqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()   \u001b[39m# transform tensor into numpy array\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(preds\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)):\n\u001b[1;32m     20\u001b[0m     predicted_label \u001b[39m=\u001b[39m preds[i] \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segmentation_path = '/home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar'\n",
    "cam_filepath = 'CAM_list.pickle'\n",
    "\n",
    "for threshold in [0.6, 0.7, 0.8, 0.9]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################Threshold:0.73###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:46<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.3153304174582409\n",
      "metric value: 0.868\n",
      "precision: 0.8031\n",
      "recall: 0.975\n",
      "estimated_area: 23378\n",
      "true_area: 23383.006718749966\n",
      "ratio (est / true): 0.9997858821660454\n",
      "error ((est - true) / true): -0.00021411783395467005\n",
      "###################Threshold:0.75###################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▊                                                     | 893/2000 [00:16<00:20, 54.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m [\u001b[39m0.73\u001b[39m, \u001b[39m0.75\u001b[39m, \u001b[39m0.77\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m###################Threshold:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m###################\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(threshold))\n\u001b[0;32m----> 3\u001b[0m     run_val(segmentation_path, threshold, cam_filepath)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mrun_val\u001b[0;34m(segmentation_path, seg_threshold, CAM_filepath)\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_existing_params(segmentation_path)\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m stats, metric_value, CAM_list, estimated_area, true_area \u001b[39m=\u001b[39m test_model(model, dataloader_test, metrics, class_threshold\u001b[39m=\u001b[39;49mclass_threshold, seg_threshold\u001b[39m=\u001b[39;49mseg_threshold, true_cam_threshold\u001b[39m=\u001b[39;49mtrue_cam_threshold)\n\u001b[1;32m     16\u001b[0m precision \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n\u001b[1;32m     17\u001b[0m recall \u001b[39m=\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (stats[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m stats[\u001b[39m'\u001b[39m\u001b[39mFN\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.00001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold)\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     _, outputs, CAM \u001b[39m=\u001b[39m model(inputs, testing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)   \u001b[39m# CAM is a 1 x 35 x 35 activation map\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     prob \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     preds \u001b[39m=\u001b[39m prob[:, \u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m class_threshold\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:51\u001b[0m, in \u001b[0;36mInceptionSegmentation.forward\u001b[0;34m(self, x, testing)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, testing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     logits, intermediate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minception3(x)\n\u001b[1;32m     52\u001b[0m     feature_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvolution1(intermediate)  \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     feature_map \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(feature_map)          \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:177\u001b[0m, in \u001b[0;36mInception3_modified.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMixed_6a(x)\n\u001b[1;32m    176\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMixed_6b(x)\n\u001b[1;32m    178\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[1;32m    179\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMixed_6c(x)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:285\u001b[0m, in \u001b[0;36mInceptionC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x)\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(outputs, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:275\u001b[0m, in \u001b[0;36mInceptionC._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_2(branch7x7dbl)\n\u001b[1;32m    274\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_3(branch7x7dbl)\n\u001b[0;32m--> 275\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbranch7x7dbl_4(branch7x7dbl)\n\u001b[1;32m    276\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_5(branch7x7dbl)\n\u001b[1;32m    278\u001b[0m branch_pool \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mavg_pool2d(x, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:407\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    405\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x)\n\u001b[1;32m    406\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(x, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:1455\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, inplace\u001b[39m=\u001b[39minplace)\n\u001b[1;32m   1454\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for threshold in [0.73, 0.75, 0.77]:\n",
    "    print('###################Threshold:{}###################'.format(threshold))\n",
    "    run_val(segmentation_path, threshold, cam_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test_model(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold):\n",
    "    stats = {'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0}\n",
    "    estimated_area = 0\n",
    "    true_area = 0\n",
    "    model.eval()\n",
    "    CAM_list = []\n",
    "    true_CAM_list = []\n",
    "    iou = []\n",
    "    for inputs, labels, paths in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            _, outputs, CAM = model(inputs, testing=True)   # CAM is a 1 x 35 x 35 activation map\n",
    "            prob = F.softmax(outputs, dim=1)\n",
    "            preds = prob[:, 1] >= class_threshold\n",
    "\n",
    "        CAM = CAM.squeeze(0).cpu().numpy()   # transform tensor into numpy array\n",
    "        for i in range(preds.size(0)):\n",
    "            predicted_label = preds[i] \n",
    "            # if labels[i]==1: # oracle to see how much improving classification would improve estimation\n",
    "            if predicted_label.cpu().item():\n",
    "                CAM_list.append((CAM, paths[i]))        # only use the generated CAM if it is predicted to be 1\n",
    "                CAM_rescaled = (CAM - CAM.min()) / (CAM.max() - CAM.min())    # get predicted area\n",
    "                CAM_pred = CAM_rescaled > seg_threshold\n",
    "                pred_pixel_area = np.sum(CAM_pred)\n",
    "                estimated_area += pred_pixel_area\n",
    "                \n",
    "            else:\n",
    "                CAM_pred = np.zeros_like(CAM)\n",
    "                CAM_list.append((np.zeros_like(CAM), paths[i]))  # otherwise the CAM is a totally black one\n",
    "\n",
    "            if labels[i] == 1:\n",
    "                # calculate true area\n",
    "                img_path = os.path.splitext(paths[i])\n",
    "                true_seg_path = img_path[0] + '_true_seg' + img_path[1]\n",
    "                true_seg_img = Image.open(true_seg_path)\n",
    "                transform = transforms.Compose([transforms.ToTensor()])\n",
    "                true_seg = transform(true_seg_img)\n",
    "                true_seg = true_seg.squeeze(0).cpu().numpy()\n",
    "                true_pixel_area = np.sum(true_seg)\n",
    "                true_pixel_area = true_pixel_area * (35. * 35.) / (true_seg.shape[0] * true_seg.shape[1])\n",
    "                true_area += true_pixel_area\n",
    "                CAM_true = skimage.transform.resize(true_seg, (35,35))\n",
    "                CAM_true = CAM_true > true_cam_threshold\n",
    "\n",
    "            else:\n",
    "                CAM_true = np.zeros_like(CAM)\n",
    "                true_CAM_list.append((CAM_true, paths[i]))\n",
    "\n",
    "        intersection = CAM_true * CAM_pred\n",
    "        union = CAM_true + CAM_pred\n",
    "        if union.sum() > 0:\n",
    "            iou.append(intersection.sum() / float(union.sum()))\n",
    "\n",
    "        stats['TP'] += torch.sum((preds == 1) * (labels == 1)).cpu().item()\n",
    "        stats['TN'] += torch.sum((preds == 0) * (labels == 0)).cpu().item()\n",
    "        stats['FP'] += torch.sum((preds == 1) * (labels == 0)).cpu().item()\n",
    "        stats['FN'] += torch.sum((preds == 0) * (labels == 1)).cpu().item()\n",
    "\n",
    "    mean_iou = np.mean(iou)\n",
    "    metric_value = metrics(stats)\n",
    "    return stats, mean_iou, CAM_list, true_CAM_list, estimated_area, true_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(segmentation_path, seg_threshold, cam_filepath, data_dir, mode):\n",
    "    if mode=='eval':\n",
    "        print('evaluating on test set')\n",
    "        dataset_test = ImageFolderModifiedEvaluation(data_dir, transform_test)\n",
    "    else:\n",
    "        dataset_test = ImageFolderModified(data_dir, transform_test)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # model\n",
    "    model = InceptionSegmentation(num_outputs=2, level=level)\n",
    "    model.load_existing_params(segmentation_path)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    stats, iou, CAM_list, true_CAM_list, estimated_area, true_area = test_model(model, dataloader_test, metrics, class_threshold=class_threshold, seg_threshold=seg_threshold, true_cam_threshold=true_cam_threshold)\n",
    "\n",
    "    cams = {'true': true_CAM_list,\n",
    "            'pred': CAM_list}\n",
    "    # dump CAM to file\n",
    "    with open(cam_filepath, 'wb') as f:\n",
    "        pickle.dump(cams, f)\n",
    "    print(\"Saved CAMs to \" + cam_filepath)\n",
    "\n",
    "    prec = precision(stats)\n",
    "    rec = recall(stats)\n",
    "    acc = metrics(stats)\n",
    "    area_fractional_error = (estimated_area - true_area) / true_area\n",
    "    \n",
    "    print('accuracy: '+str(acc))\n",
    "    print('precision: ' + str(round(prec, 4)))\n",
    "    print('recall: ' + str(round(rec, 4)))\n",
    "    print('iou: ' + str(iou))\n",
    "    print('estimated_area: ' + str(estimated_area))\n",
    "    print('true_area: ' + str(true_area))\n",
    "    print('error ((est - true) / true): ' + str(area_fractional_error))\n",
    "\n",
    "    return (acc, prec, rec, iou, area_fractional_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = ['baseline', 'ft_100', 'ft_500', 'ft_1000', 'ft_5000']\n",
    "SEGMENTATION_PATHS = [\n",
    "    '/home/ubuntu/deepsolar/models/deepsolar_seg_pretrained.pth',\n",
    "    '/home/ubuntu/deepsolar/checkpoint/ft_100_segmentation_level_2_sweep_best_models/psel_0_lr_0-0004228521209106932_lr_decay_rate_0-1180038312075688_weight_decay_0-2207810660245898_epoch__8_last.tar',\n",
    "    '/home/ubuntu/deepsolar/checkpoint/ft_500_segmentation_level_2_tune_sweep_best_models/psel_0-8188110871270571_lr_0-0008709800586192774_lr_decay_rate_0-4240342150652191_weight_decay_0-2204940780344005_epoch__9_last.tar',\n",
    "    '/home/ubuntu/deepsolar/checkpoint/ft_1000_segmentation_level_2_tune_sweep_best_models/psel_0-7246077310839052_lr_0-0006188732400968487_lr_decay_rate_0-33457774028832415_weight_decay_0-05248446740883417_epoch__10_last.tar',\n",
    "    '/home/ubuntu/deepsolar/checkpoint/ft_5000_segmentation_level_2_tune_sweep_best_models/psel_0-6956991453638643_lr_0-0002431815776062007_lr_decay_rate_0-3461895018894605_weight_decay_0-07219288691242215_epoch__0_last.tar'\n",
    "]\n",
    "SEGMENTATION_THRESHOLDS = [0.37, 0.73, 0.77, 0.86, 0.73]\n",
    "FR_EVAL_DATA = '/home/ubuntu/deepsolar/data/ds-france/google/ft_eval'\n",
    "US_EVAL_DATA = '/home/ubuntu/deepsolar/data/ds-usa/eval'\n",
    "\n",
    "NAMES = ['baseline']\n",
    "SEGMENTATION_PATHS = [\n",
    "    '/home/ubuntu/deepsolar/models/deepsolar_seg_pretrained.pth',\n",
    "]\n",
    "SEGMENTATION_THRESHOLDS = [0.37]\n",
    "FR_EVAL_DATA = '/home/ubuntu/deepsolar/data/ds-france/google/ft_eval'\n",
    "US_EVAL_DATA = '/home/ubuntu/deepsolar/data/ds-usa/eval'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################ Evaluating baseline on fr eval dataset #######################################\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/models/deepsolar_seg_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:58<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAMs to CAM_list_baseline_fr_eval.pickle\n",
      "accuracy: 0.5654\n",
      "precision: 0.9619\n",
      "recall: 0.1362\n",
      "iou: 0.06102155351183272\n",
      "estimated_area: 30887\n",
      "true_area: 116490.46390625011\n",
      "error ((est - true) / true): -0.734853832972479\n",
      "############################ Evaluating baseline on us eval dataset #######################################\n",
      "evaluating on test set\n",
      "Loaded existing model parameters from: /home/ubuntu/deepsolar/models/deepsolar_seg_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████                                                                               | 14114/93500 [04:24<24:46, 53.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████▎                                                                        | 20435/93500 [06:21<22:44, 53.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m############################ Evaluating \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m eval dataset #######################################\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, ds_name))\n\u001b[1;32m     12\u001b[0m cam_filepath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCAM_list_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m ds_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_eval.pickle\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m acc, prec, rec, iou, area_fractional_error \u001b[39m=\u001b[39m run_eval(path, seg_threshold, cam_filepath, data_dir, mode)\n\u001b[1;32m     14\u001b[0m names\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m     15\u001b[0m accs\u001b[39m.\u001b[39mappend(acc)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(segmentation_path, seg_threshold, cam_filepath, data_dir, mode)\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_existing_params(segmentation_path)\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m stats, iou, CAM_list, true_CAM_list, estimated_area, true_area \u001b[39m=\u001b[39m test_model(model, dataloader_test, metrics, class_threshold\u001b[39m=\u001b[39;49mclass_threshold, seg_threshold\u001b[39m=\u001b[39;49mseg_threshold, true_cam_threshold\u001b[39m=\u001b[39;49mtrue_cam_threshold)\n\u001b[1;32m     17\u001b[0m cams \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m: true_CAM_list,\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m: CAM_list}\n\u001b[1;32m     19\u001b[0m \u001b[39m# dump CAM to file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, dataloader, metrics, class_threshold, seg_threshold, true_cam_threshold)\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     _, outputs, CAM \u001b[39m=\u001b[39m model(inputs, testing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)   \u001b[39m# CAM is a 1 x 35 x 35 activation map\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     prob \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     preds \u001b[39m=\u001b[39m prob[:, \u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m class_threshold\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:51\u001b[0m, in \u001b[0;36mInceptionSegmentation.forward\u001b[0;34m(self, x, testing)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, testing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     logits, intermediate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minception3(x)\n\u001b[1;32m     52\u001b[0m     feature_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvolution1(intermediate)  \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     feature_map \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(feature_map)          \u001b[39m# N x 512 x 35 x 35\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/deepsolar/src/inception_modified.py:183\u001b[0m, in \u001b[0;36mInception3_modified.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    181\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMixed_6d(x)\n\u001b[1;32m    182\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMixed_6e(x)\n\u001b[1;32m    184\u001b[0m \u001b[39m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maux_logits:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:285\u001b[0m, in \u001b[0;36mInceptionC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x)\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(outputs, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:276\u001b[0m, in \u001b[0;36mInceptionC._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_3(branch7x7dbl)\n\u001b[1;32m    275\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch7x7dbl_4(branch7x7dbl)\n\u001b[0;32m--> 276\u001b[0m branch7x7dbl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbranch7x7dbl_5(branch7x7dbl)\n\u001b[1;32m    278\u001b[0m branch_pool \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mavg_pool2d(x, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    279\u001b[0m branch_pool \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbranch_pool(branch_pool)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/inception.py:406\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    405\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x)\n\u001b[0;32m--> 406\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn(x)\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mrelu(x, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = []\n",
    "accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "ious = []\n",
    "area_fractional_errors = []\n",
    "ds_names = []\n",
    "\n",
    "for name, path, seg_threshold in zip(NAMES, SEGMENTATION_PATHS, SEGMENTATION_THRESHOLDS):\n",
    "    for ds_name, data_dir, mode in zip(['fr', 'us'], [FR_EVAL_DATA, US_EVAL_DATA], ['val', 'eval']):\n",
    "        print(\"############################ Evaluating {} on {} eval dataset #######################################\".format(name, ds_name))\n",
    "        cam_filepath = 'CAM_list_' + name + '_' + ds_name + '_eval.pickle'\n",
    "        acc, prec, rec, iou, area_fractional_error = run_eval(path, seg_threshold, cam_filepath, data_dir, mode)\n",
    "        names.append(name)\n",
    "        accs.append(acc)\n",
    "        precs.append(prec)\n",
    "        recs.append(rec)\n",
    "        ious.append(iou)\n",
    "        area_fractional_errors.append(area_fractional_error)\n",
    "        ds_names.append(ds_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.Dataframe(zip(names, ds_names, accs, precs, recs, ious, area_fractional_errors), \n",
    "                    columns = ['model', 'eval ds', 'accuracy', 'precision', 'recall', 'iou', 'area_fractional_error'])\n",
    "\n",
    "results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
