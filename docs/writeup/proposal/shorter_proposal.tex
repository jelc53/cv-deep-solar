\documentclass{article}

\usepackage[final]{neurips_2019}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage[left=1.5cm, right=1.5cm]{geometry}

\newcommand{\note}[1]{\textcolor{blue}{{#1}}}

\title{
  Improving a Rooftop Solar Panel Segmentation Model's Robustness to Domain Shifts \\
  \vspace{0.15cm}
  {\normalfont Stanford CS231N Project}  
}

\author{
  Kerrie Wu \\
  % ICME \\
  Stanford University \\
  \texttt{kerriewu@stanford.edu} \\
  % Examples of more authors
   \And
    Julian Cooper \\
  % ICME \\
  Stanford University \\
  \texttt{jelc@stanford.edu} \\
   \And
   Andrea van den Haak \\
  % ICME \\
  Stanford University \\
  \texttt{vandenhaak@stanford.edu} \\
}

\begin{document}

\maketitle

% \begin{abstract}
%   Required for final report
% \end{abstract}

% \note{This template is built on NeurIPS 2019 template\footnote{\url{https://www.overleaf.com/latex/templates/neurips-2019/tprktwxmqmgk}} and provided for your convenience.}
% \vspace{-0.7cm}

% \newline
\textbf{Problem \& Motivation.}
We are interested in segmenting and classifying rooftop solar panels from satellite images, with a focus on residential areas. The worldwide rollout of rooftop solar has been largely untracked. Being able to estimate this allows utilities to predict power output and better manage the grid and investments.

Stanford's DeepSolar team have largely solved this challenge for the United States \cite{DeepSolar1} \cite{DeepSolar2}, but their model is not robust to "distribution shifts", meaning the accuracy drops when tested on datasets from other regions. We want to investigate different techniques for modifying the DeepSolar segmentation model in order to improve its robustness to distribution shifts. \\

\textbf{Dataset \& Evaluation.}
Kasmi et al \cite{Kasmi2023} recently published a labelled rooftop solar dataset for France (released January 2023) which provides ground truth segmentation masks for 13303 images from Google Earth25 and 7686 images from the French national institute of geographical and forestry information (IGN). We will use this to test our model's ability to handle distribution shifts by training our model on United States data, but validating and testing our model on France data. We will use effective robustness and relative robustness (as defined by \cite{Taori2020}) to measure the effectiveness of our approaches, and DICE/F1 scores to measure segmentation model performance irrespective of robustness. \\

\textbf{Literature Review.}
In addition to reviewing the France dataset and DeepSolar codebase, we have also read several papers on techniques for measuring robustness to and handling distribution shift.

\begin{itemize}
    \item Taori, 2020 \cite{Taori2020}: Major contributions included defining effective robustness and relative robustness metrics. 
    \item Yao, 2022 \cite{yao2022improving}: Describes a data augmentation method called LISA adds interpolations between original input-output training example pairs to the training data, selected in a way that improves robustness to domain shifts.
    \item Volpi, 2018 \cite{volpi2018generalizing}: Describes how to adversarially augment the training data to achieve a more robust model. 
    \item Huang, 2022 \cite{huang2022online}: Describes RefSeq, a method that involves training a separate proxy segmentation-generating model in addition to the main segmentation model, and asking the main segmentation model to "reflect" and refine on its originally predicted segmentation given the proxy segmentation, to achieve a better result at test time. 
\end{itemize}

\textbf{Proposed Modeling Approach.} 
Some of the approaches that we plan to try are interpolation-based data augmentation through LISA \cite{yao2022improving}, regularized fine-tuning \cite{li2021}, adversarial data augmentation \cite{volpi2018generalizing}, and test-time/training adaptation methods involving auxiliary models such as RefSeq \cite{huang2022online}. We expect that our experiments will yield plots comparing robustness metrics and DICE/F1 scores across different approaches.

\bibliographystyle{unsrt}
\bibliography{references}



\end{document}
